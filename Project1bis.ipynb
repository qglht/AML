{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a96534f8",
   "metadata": {},
   "source": [
    "# Project 1 - Aurèle Bohbot, Quentin Guilhot, Yanis Tournier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e3410cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as skl\n",
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, ShuffleSplit\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LassoCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "bfbfee1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('data/X_train.csv').drop(columns=['id'])\n",
    "Xt = pd.read_csv('data/X_test.csv')\n",
    "y = pd.read_csv('data/y_train.csv')\n",
    "y = y.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "06c242f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e9c628b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of samples \n",
    "n_samples = X_train.shape[0]\n",
    "n_features = X_train.shape[1]\n",
    "\n",
    "# number of maximum features\n",
    "n_max_features = int(np.sqrt(n_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0027aad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_max_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8774a89e",
   "metadata": {},
   "source": [
    "### Experimental section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21330ecf",
   "metadata": {},
   "source": [
    "#### Normalization of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "390e4762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing X_train\n",
    "\n",
    "X_train_norm = X_train.copy()\n",
    "for col in X_train.columns:\n",
    "    X_train_norm[col] = (X_train[col] - X_train[col].mean()) / X_train[col].std()\n",
    "\n",
    "# normalizing X_test\n",
    "X_test_norm = X_test.copy()\n",
    "for col in X_test.columns:\n",
    "    X_test_norm[col] = (X_test[col] - X_test[col].mean()) / X_test[col].std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "353d88c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning of X_train\n",
    "\n",
    "X_train_norm=X_train_norm.fillna(X_train_norm.median())\n",
    "\n",
    "# cleaning of X_test\n",
    "\n",
    "X_test_norm=X_test_norm.fillna(X_test_norm.median())\n",
    "\n",
    "# removing columns for which there are only nans\n",
    "\n",
    "columns_to_remove = []\n",
    "for column in X_test_norm.columns:\n",
    "    if X_test_norm[column].isna().sum() > 0 or X_train_norm[column].isna().sum():\n",
    "        columns_to_remove.append(column)\n",
    "\n",
    "X_train_norm.drop(columns_to_remove, inplace=True, axis=1)\n",
    "X_test_norm.drop(columns_to_remove, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d372e4f",
   "metadata": {},
   "source": [
    "First regression without any additional treatment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4093b811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.019188489565065137"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=LinearRegression()\n",
    "model.fit(X_train_norm,y_train)\n",
    "\n",
    "y_pred=model.predict(X_test_norm)\n",
    "r2_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d195b056",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "032f1732",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=n_max_features)\n",
    "X_train_norm = pca.fit_transform(X_train_norm)\n",
    "X_test_norm = pca.transform(X_test_norm)\n",
    "explained_variance = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c91b7d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27286401474106725\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(explained_variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c1c38412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(848, 29)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "33e138b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.094267018234106"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=LinearRegression()\n",
    "model.fit(X_train_norm,y_train)\n",
    "\n",
    "y_pred=model.predict(X_test_norm)\n",
    "r2_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f4b0ac",
   "metadata": {},
   "source": [
    "### Handling outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "10209367",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.covariance import EllipticEnvelope\n",
    "pred = EllipticEnvelope(random_state=0).fit_predict(X_train_norm)\n",
    "outlier_index = np.where(pred==-1)\n",
    "outlier_values = X_train_norm[outlier_index]\n",
    "inlier_index = np.where(pred==1)\n",
    "X_train_norm_inliers = X_train_norm[inlier_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8f4823c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(763, 29)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_norm_inliers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "82ea1a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "inlier_index = np.where(pred==1)\n",
    "X_train_norm_inliers = X_train_norm[inlier_index]\n",
    "y_train_inliers = y_train[y_train.index.isin([y_train.index[i] for i in range(len(y_train.index)) if i in list(inlier_index[0])])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8134febf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33084901266568156"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train_norm_inliers, y_train_inliers)\n",
    "y_pred = model.predict(X_test_norm)\n",
    "y_pred.shape\n",
    "score = r2_score(y_test, y_pred)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7ed81b23",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([ 874,  670,  931,  482,  927,  947,  548,  354, 1060,  423,\\n            ...\\n            1123,   87,  330,  466,  121, 1044, 1095, 1130,  860, 1126],\\n           dtype='int64', length=848)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/qguilhot/Documents/projet_aml/AML/Project1bis.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/qguilhot/Documents/projet_aml/AML/Project1bis.ipynb#Y121sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m y_train \u001b[39m=\u001b[39m y_train[y_train\u001b[39m.\u001b[39;49mindex]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aml/lib/python3.10/site-packages/pandas/core/frame.py:3511\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3509\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3510\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 3511\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   3513\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3514\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aml/lib/python3.10/site-packages/pandas/core/indexes/base.py:5796\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5793\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   5794\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5796\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   5798\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   5799\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5800\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aml/lib/python3.10/site-packages/pandas/core/indexes/base.py:5856\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5854\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   5855\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 5856\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   5858\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m   5859\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Int64Index([ 874,  670,  931,  482,  927,  947,  548,  354, 1060,  423,\\n            ...\\n            1123,   87,  330,  466,  121, 1044, 1095, 1130,  860, 1126],\\n           dtype='int64', length=848)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "y_train = y_train[y_train.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28a6118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection(df,features):\n",
    "    outlier_indices=[]\n",
    "    \n",
    "    for c in features:\n",
    "        Q1, Q3 = np.percentile(df[c],25), np.percentile(df[c],75)\n",
    "        \n",
    "        #IQR calculation\n",
    "        IQR = Q3 - Q1\n",
    "        outlier_step = IQR * 1.5\n",
    "        lower_range = Q1 - (outlier_step)\n",
    "        upper_range = Q3 + (outlier_step)\n",
    "        \n",
    "        #Outlier detection                                    #Outlier indexes\n",
    "        outlier_list_col=df[  (df[c] < lower_range) | (df[c] > upper_range)  ].index\n",
    "       \n",
    "        #Store indexes\n",
    "        outlier_indices.extend(outlier_list_col)\n",
    "        \n",
    "    outlier_indices=Counter(outlier_indices)\n",
    "    # number of outliers\n",
    "    # If we have more then 2 outliers in a sample, this sample ll be drop\n",
    "    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 2 )\n",
    "    #we are taking indexes\n",
    "    \n",
    "    return multiple_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9624a01e",
   "metadata": {},
   "source": [
    "### Handling missing values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67ed714",
   "metadata": {},
   "source": [
    "For the moment, we replace the missing values by the column's median. Depending on the results, we might implement a knn algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0189f882",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filled = X_train.fillna(X_train.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc10528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x822</th>\n",
       "      <th>x823</th>\n",
       "      <th>x824</th>\n",
       "      <th>x825</th>\n",
       "      <th>x826</th>\n",
       "      <th>x827</th>\n",
       "      <th>x828</th>\n",
       "      <th>x829</th>\n",
       "      <th>x830</th>\n",
       "      <th>x831</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>-0.000191</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>-0.154380</td>\n",
       "      <td>-0.009335</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>-0.002417</td>\n",
       "      <td>0.003107</td>\n",
       "      <td>0.777743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.006812</td>\n",
       "      <td>0.384590</td>\n",
       "      <td>-0.140845</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>3.768914</td>\n",
       "      <td>-0.006653</td>\n",
       "      <td>-0.021844</td>\n",
       "      <td>0.001487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>-0.000021</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000148</td>\n",
       "      <td>-0.000141</td>\n",
       "      <td>0.505886</td>\n",
       "      <td>0.092102</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>-0.000460</td>\n",
       "      <td>-0.004630</td>\n",
       "      <td>0.433480</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001007</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>0.005971</td>\n",
       "      <td>-0.003462</td>\n",
       "      <td>0.399401</td>\n",
       "      <td>0.001831</td>\n",
       "      <td>0.524528</td>\n",
       "      <td>-0.000215</td>\n",
       "      <td>-0.002161</td>\n",
       "      <td>0.000899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000724</td>\n",
       "      <td>-0.002035</td>\n",
       "      <td>-0.000286</td>\n",
       "      <td>0.137264</td>\n",
       "      <td>-0.073407</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.004557</td>\n",
       "      <td>0.005539</td>\n",
       "      <td>1.515610</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000212</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>-0.641024</td>\n",
       "      <td>0.277172</td>\n",
       "      <td>-0.000523</td>\n",
       "      <td>2.442379</td>\n",
       "      <td>-0.008166</td>\n",
       "      <td>-0.062831</td>\n",
       "      <td>0.000397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>-0.000035</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>-0.000260</td>\n",
       "      <td>-0.000093</td>\n",
       "      <td>-0.559518</td>\n",
       "      <td>0.052546</td>\n",
       "      <td>-0.001279</td>\n",
       "      <td>-0.002651</td>\n",
       "      <td>0.001732</td>\n",
       "      <td>-0.117031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001693</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.003330</td>\n",
       "      <td>0.042626</td>\n",
       "      <td>0.240126</td>\n",
       "      <td>-0.002526</td>\n",
       "      <td>-0.540456</td>\n",
       "      <td>-0.006263</td>\n",
       "      <td>-0.014049</td>\n",
       "      <td>-0.000402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>-0.650713</td>\n",
       "      <td>-0.166438</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>1.636243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001827</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.002366</td>\n",
       "      <td>0.556094</td>\n",
       "      <td>0.348091</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>-3.817613</td>\n",
       "      <td>-0.005040</td>\n",
       "      <td>-0.051506</td>\n",
       "      <td>-0.000167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>-0.000017</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>-0.000747</td>\n",
       "      <td>-0.000146</td>\n",
       "      <td>-0.299233</td>\n",
       "      <td>-0.074816</td>\n",
       "      <td>0.001337</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.002046</td>\n",
       "      <td>-0.035358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>-0.000556</td>\n",
       "      <td>0.597515</td>\n",
       "      <td>-0.241668</td>\n",
       "      <td>0.001819</td>\n",
       "      <td>-0.548766</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>0.010332</td>\n",
       "      <td>0.001732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>-0.000130</td>\n",
       "      <td>-0.000578</td>\n",
       "      <td>-0.001493</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>-0.291664</td>\n",
       "      <td>-0.044665</td>\n",
       "      <td>-0.002494</td>\n",
       "      <td>0.004691</td>\n",
       "      <td>-0.004626</td>\n",
       "      <td>-0.531617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>-0.001333</td>\n",
       "      <td>-0.554086</td>\n",
       "      <td>0.021501</td>\n",
       "      <td>0.001412</td>\n",
       "      <td>5.425245</td>\n",
       "      <td>-0.005304</td>\n",
       "      <td>-0.047635</td>\n",
       "      <td>-0.001013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>-0.000310</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>-0.001574</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.501948</td>\n",
       "      <td>0.019427</td>\n",
       "      <td>-0.000673</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.005545</td>\n",
       "      <td>0.605537</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000169</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>-0.000556</td>\n",
       "      <td>-0.217587</td>\n",
       "      <td>0.430237</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>1.563517</td>\n",
       "      <td>0.002265</td>\n",
       "      <td>0.041897</td>\n",
       "      <td>0.000199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.003753</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.597933</td>\n",
       "      <td>-0.023415</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>-0.000490</td>\n",
       "      <td>-0.001070</td>\n",
       "      <td>-0.840170</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.007744</td>\n",
       "      <td>-0.231753</td>\n",
       "      <td>0.597580</td>\n",
       "      <td>0.003269</td>\n",
       "      <td>1.454245</td>\n",
       "      <td>0.003957</td>\n",
       "      <td>-0.007954</td>\n",
       "      <td>-0.002471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>0.000693</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.252289</td>\n",
       "      <td>-0.003574</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.005636</td>\n",
       "      <td>0.372498</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000402</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>-0.000556</td>\n",
       "      <td>-0.087948</td>\n",
       "      <td>-0.427408</td>\n",
       "      <td>0.001313</td>\n",
       "      <td>-4.163956</td>\n",
       "      <td>-0.000367</td>\n",
       "      <td>0.002830</td>\n",
       "      <td>0.000080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>848 rows × 832 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x0        x1        x2        x3        x4        x5        x6  \\\n",
       "874  -0.000191 -0.000015  0.001862  0.000215 -0.154380 -0.009335  0.002314   \n",
       "670  -0.000021 -0.000237 -0.000148 -0.000141  0.505886  0.092102  0.000029   \n",
       "931  -0.000013 -0.000724 -0.002035 -0.000286  0.137264 -0.073407  0.000816   \n",
       "482  -0.000035  0.000053 -0.000260 -0.000093 -0.559518  0.052546 -0.001279   \n",
       "927   0.000057  0.000565  0.000552  0.000201 -0.650713 -0.166438  0.000268   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1044 -0.000017  0.000201 -0.000747 -0.000146 -0.299233 -0.074816  0.001337   \n",
       "1095 -0.000130 -0.000578 -0.001493  0.000049 -0.291664 -0.044665 -0.002494   \n",
       "1130 -0.000310 -0.000022 -0.001574 -0.000002  0.501948  0.019427 -0.000673   \n",
       "860   0.000509  0.001001  0.003753  0.000035  0.597933 -0.023415  0.001096   \n",
       "1126  0.000693  0.000700  0.001019  0.000113  0.252289 -0.003574  0.000227   \n",
       "\n",
       "            x7        x8        x9  ...      x822      x823      x824  \\\n",
       "874  -0.002417  0.003107  0.777743  ...  0.001009  0.000014  0.006812   \n",
       "670  -0.000460 -0.004630  0.433480  ... -0.001007 -0.000066  0.005971   \n",
       "931   0.004557  0.005539  1.515610  ... -0.000212  0.000161  0.000315   \n",
       "482  -0.002651  0.001732 -0.117031  ...  0.001693  0.000398  0.003330   \n",
       "927   0.004325 -0.000078  1.636243  ... -0.001827  0.000439  0.002366   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1044  0.000294  0.002046 -0.035358  ...  0.000124  0.000096 -0.000556   \n",
       "1095  0.004691 -0.004626 -0.531617  ...  0.000950  0.000117 -0.001333   \n",
       "1130  0.000029  0.005545  0.605537  ... -0.000169  0.000546 -0.000556   \n",
       "860  -0.000490 -0.001070 -0.840170  ... -0.002403  0.000560  0.007744   \n",
       "1126  0.000029  0.005636  0.372498  ... -0.000402  0.000103 -0.000556   \n",
       "\n",
       "          x825      x826      x827      x828      x829      x830      x831  \n",
       "874   0.384590 -0.140845  0.000306  3.768914 -0.006653 -0.021844  0.001487  \n",
       "670  -0.003462  0.399401  0.001831  0.524528 -0.000215 -0.002161  0.000899  \n",
       "931  -0.641024  0.277172 -0.000523  2.442379 -0.008166 -0.062831  0.000397  \n",
       "482   0.042626  0.240126 -0.002526 -0.540456 -0.006263 -0.014049 -0.000402  \n",
       "927   0.556094  0.348091  0.001144 -3.817613 -0.005040 -0.051506 -0.000167  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1044  0.597515 -0.241668  0.001819 -0.548766 -0.000014  0.010332  0.001732  \n",
       "1095 -0.554086  0.021501  0.001412  5.425245 -0.005304 -0.047635 -0.001013  \n",
       "1130 -0.217587  0.430237  0.000164  1.563517  0.002265  0.041897  0.000199  \n",
       "860  -0.231753  0.597580  0.003269  1.454245  0.003957 -0.007954 -0.002471  \n",
       "1126 -0.087948 -0.427408  0.001313 -4.163956 -0.000367  0.002830  0.000080  \n",
       "\n",
       "[848 rows x 832 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_norm = X_filled.copy()\n",
    "for col in X_filled.columns:\n",
    "    X_train_norm[col] = (X_filled[col] - X_filled[col].mean()) / X_filled[col].var()\n",
    "X_train_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7814c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x822</th>\n",
       "      <th>x823</th>\n",
       "      <th>x824</th>\n",
       "      <th>x825</th>\n",
       "      <th>x826</th>\n",
       "      <th>x827</th>\n",
       "      <th>x828</th>\n",
       "      <th>x829</th>\n",
       "      <th>x830</th>\n",
       "      <th>x831</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>-0.000191</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>-0.154380</td>\n",
       "      <td>-0.009335</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>-0.002417</td>\n",
       "      <td>0.003107</td>\n",
       "      <td>0.777743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.006812</td>\n",
       "      <td>0.384590</td>\n",
       "      <td>-0.140845</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>3.768914</td>\n",
       "      <td>-0.006653</td>\n",
       "      <td>-0.021844</td>\n",
       "      <td>0.001487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>-0.000021</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.000148</td>\n",
       "      <td>-0.000141</td>\n",
       "      <td>0.505886</td>\n",
       "      <td>0.092102</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>-0.000460</td>\n",
       "      <td>-0.004630</td>\n",
       "      <td>0.433480</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001007</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>0.005971</td>\n",
       "      <td>-0.003462</td>\n",
       "      <td>0.399401</td>\n",
       "      <td>0.001831</td>\n",
       "      <td>0.524528</td>\n",
       "      <td>-0.000215</td>\n",
       "      <td>-0.002161</td>\n",
       "      <td>0.000899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000724</td>\n",
       "      <td>-0.002035</td>\n",
       "      <td>-0.000286</td>\n",
       "      <td>0.137264</td>\n",
       "      <td>-0.073407</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.004557</td>\n",
       "      <td>0.005539</td>\n",
       "      <td>1.515610</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000212</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>-0.641024</td>\n",
       "      <td>0.277172</td>\n",
       "      <td>-0.000523</td>\n",
       "      <td>2.442379</td>\n",
       "      <td>-0.008166</td>\n",
       "      <td>-0.062831</td>\n",
       "      <td>0.000397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>-0.000035</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>-0.000260</td>\n",
       "      <td>-0.000093</td>\n",
       "      <td>-0.559518</td>\n",
       "      <td>0.052546</td>\n",
       "      <td>-0.001279</td>\n",
       "      <td>-0.002651</td>\n",
       "      <td>0.001732</td>\n",
       "      <td>-0.117031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001693</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.003330</td>\n",
       "      <td>0.042626</td>\n",
       "      <td>0.240126</td>\n",
       "      <td>-0.002526</td>\n",
       "      <td>-0.540456</td>\n",
       "      <td>-0.006263</td>\n",
       "      <td>-0.014049</td>\n",
       "      <td>-0.000402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>-0.650713</td>\n",
       "      <td>-0.166438</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>1.636243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001827</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.002366</td>\n",
       "      <td>0.556094</td>\n",
       "      <td>0.348091</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>-3.817613</td>\n",
       "      <td>-0.005040</td>\n",
       "      <td>-0.051506</td>\n",
       "      <td>-0.000167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>-0.000017</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>-0.000747</td>\n",
       "      <td>-0.000146</td>\n",
       "      <td>-0.299233</td>\n",
       "      <td>-0.074816</td>\n",
       "      <td>0.001337</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.002046</td>\n",
       "      <td>-0.035358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>-0.000556</td>\n",
       "      <td>0.597515</td>\n",
       "      <td>-0.241668</td>\n",
       "      <td>0.001819</td>\n",
       "      <td>-0.548766</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>0.010332</td>\n",
       "      <td>0.001732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>-0.000130</td>\n",
       "      <td>-0.000578</td>\n",
       "      <td>-0.001493</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>-0.291664</td>\n",
       "      <td>-0.044665</td>\n",
       "      <td>-0.002494</td>\n",
       "      <td>0.004691</td>\n",
       "      <td>-0.004626</td>\n",
       "      <td>-0.531617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>-0.001333</td>\n",
       "      <td>-0.554086</td>\n",
       "      <td>0.021501</td>\n",
       "      <td>0.001412</td>\n",
       "      <td>5.425245</td>\n",
       "      <td>-0.005304</td>\n",
       "      <td>-0.047635</td>\n",
       "      <td>-0.001013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>-0.000310</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>-0.001574</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.501948</td>\n",
       "      <td>0.019427</td>\n",
       "      <td>-0.000673</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.005545</td>\n",
       "      <td>0.605537</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000169</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>-0.000556</td>\n",
       "      <td>-0.217587</td>\n",
       "      <td>0.430237</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>1.563517</td>\n",
       "      <td>0.002265</td>\n",
       "      <td>0.041897</td>\n",
       "      <td>0.000199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.003753</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.597933</td>\n",
       "      <td>-0.023415</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>-0.000490</td>\n",
       "      <td>-0.001070</td>\n",
       "      <td>-0.840170</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.007744</td>\n",
       "      <td>-0.231753</td>\n",
       "      <td>0.597580</td>\n",
       "      <td>0.003269</td>\n",
       "      <td>1.454245</td>\n",
       "      <td>0.003957</td>\n",
       "      <td>-0.007954</td>\n",
       "      <td>-0.002471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>0.000693</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.252289</td>\n",
       "      <td>-0.003574</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.005636</td>\n",
       "      <td>0.372498</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000402</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>-0.000556</td>\n",
       "      <td>-0.087948</td>\n",
       "      <td>-0.427408</td>\n",
       "      <td>0.001313</td>\n",
       "      <td>-4.163956</td>\n",
       "      <td>-0.000367</td>\n",
       "      <td>0.002830</td>\n",
       "      <td>0.000080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>848 rows × 832 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x0        x1        x2        x3        x4        x5        x6  \\\n",
       "874  -0.000191 -0.000015  0.001862  0.000215 -0.154380 -0.009335  0.002314   \n",
       "670  -0.000021 -0.000237 -0.000148 -0.000141  0.505886  0.092102  0.000029   \n",
       "931  -0.000013 -0.000724 -0.002035 -0.000286  0.137264 -0.073407  0.000816   \n",
       "482  -0.000035  0.000053 -0.000260 -0.000093 -0.559518  0.052546 -0.001279   \n",
       "927   0.000057  0.000565  0.000552  0.000201 -0.650713 -0.166438  0.000268   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1044 -0.000017  0.000201 -0.000747 -0.000146 -0.299233 -0.074816  0.001337   \n",
       "1095 -0.000130 -0.000578 -0.001493  0.000049 -0.291664 -0.044665 -0.002494   \n",
       "1130 -0.000310 -0.000022 -0.001574 -0.000002  0.501948  0.019427 -0.000673   \n",
       "860   0.000509  0.001001  0.003753  0.000035  0.597933 -0.023415  0.001096   \n",
       "1126  0.000693  0.000700  0.001019  0.000113  0.252289 -0.003574  0.000227   \n",
       "\n",
       "            x7        x8        x9  ...      x822      x823      x824  \\\n",
       "874  -0.002417  0.003107  0.777743  ...  0.001009  0.000014  0.006812   \n",
       "670  -0.000460 -0.004630  0.433480  ... -0.001007 -0.000066  0.005971   \n",
       "931   0.004557  0.005539  1.515610  ... -0.000212  0.000161  0.000315   \n",
       "482  -0.002651  0.001732 -0.117031  ...  0.001693  0.000398  0.003330   \n",
       "927   0.004325 -0.000078  1.636243  ... -0.001827  0.000439  0.002366   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1044  0.000294  0.002046 -0.035358  ...  0.000124  0.000096 -0.000556   \n",
       "1095  0.004691 -0.004626 -0.531617  ...  0.000950  0.000117 -0.001333   \n",
       "1130  0.000029  0.005545  0.605537  ... -0.000169  0.000546 -0.000556   \n",
       "860  -0.000490 -0.001070 -0.840170  ... -0.002403  0.000560  0.007744   \n",
       "1126  0.000029  0.005636  0.372498  ... -0.000402  0.000103 -0.000556   \n",
       "\n",
       "          x825      x826      x827      x828      x829      x830      x831  \n",
       "874   0.384590 -0.140845  0.000306  3.768914 -0.006653 -0.021844  0.001487  \n",
       "670  -0.003462  0.399401  0.001831  0.524528 -0.000215 -0.002161  0.000899  \n",
       "931  -0.641024  0.277172 -0.000523  2.442379 -0.008166 -0.062831  0.000397  \n",
       "482   0.042626  0.240126 -0.002526 -0.540456 -0.006263 -0.014049 -0.000402  \n",
       "927   0.556094  0.348091  0.001144 -3.817613 -0.005040 -0.051506 -0.000167  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1044  0.597515 -0.241668  0.001819 -0.548766 -0.000014  0.010332  0.001732  \n",
       "1095 -0.554086  0.021501  0.001412  5.425245 -0.005304 -0.047635 -0.001013  \n",
       "1130 -0.217587  0.430237  0.000164  1.563517  0.002265  0.041897  0.000199  \n",
       "860  -0.231753  0.597580  0.003269  1.454245  0.003957 -0.007954 -0.002471  \n",
       "1126 -0.087948 -0.427408  0.001313 -4.163956 -0.000367  0.002830  0.000080  \n",
       "\n",
       "[848 rows x 832 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {}\n",
    "for col in X_train_norm.columns:\n",
    "    Q1, Q3 = np.percentile(X_train_norm[col],25), np.percentile(X_train_norm[col],75)\n",
    "    IQR = Q3 - Q1\n",
    "    outlier_step = IQR * 2\n",
    "    lower_range = Q1 - (outlier_step)\n",
    "    upper_range = Q3 + (outlier_step)\n",
    "    d[col] = (lower_range, upper_range)\n",
    "for i, row in X_train_norm.iterrows():\n",
    "    for col in X_train_norm.columns:\n",
    "        if row[col] < d[col][0] or row[col] > d[col][1]:\n",
    "            X_train_norm.loc[i,col]=0\n",
    "X_train_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5d3228",
   "metadata": {},
   "source": [
    "### Handling feature selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72780940",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLasso does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/qguilhot/Documents/projet_aml/AML/Project1bis.ipynb Cell 29\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/qguilhot/Documents/projet_aml/AML/Project1bis.ipynb#Y116sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m lasso \u001b[39m=\u001b[39m Lasso()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/qguilhot/Documents/projet_aml/AML/Project1bis.ipynb#Y116sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m lasso\u001b[39m.\u001b[39;49mfit(X_train_norm, y_train)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:955\u001b[0m, in \u001b[0;36mElasticNet.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[39mif\u001b[39;00m check_input:\n\u001b[1;32m    954\u001b[0m     X_copied \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy_X \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_intercept\n\u001b[0;32m--> 955\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    956\u001b[0m         X,\n\u001b[1;32m    957\u001b[0m         y,\n\u001b[1;32m    958\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    959\u001b[0m         order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mF\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    960\u001b[0m         dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32],\n\u001b[1;32m    961\u001b[0m         copy\u001b[39m=\u001b[39;49mX_copied,\n\u001b[1;32m    962\u001b[0m         multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    963\u001b[0m         y_numeric\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    964\u001b[0m     )\n\u001b[1;32m    965\u001b[0m     y \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m    966\u001b[0m         y, order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mF\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    967\u001b[0m     )\n\u001b[1;32m    969\u001b[0m n_samples, n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aml/lib/python3.10/site-packages/sklearn/base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    594\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    595\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aml/lib/python3.10/site-packages/sklearn/utils/validation.py:1074\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1069\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1070\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1071\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1072\u001b[0m     )\n\u001b[0;32m-> 1074\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1075\u001b[0m     X,\n\u001b[1;32m   1076\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m   1077\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[1;32m   1078\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1079\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[1;32m   1080\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   1081\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m   1082\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[1;32m   1083\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[1;32m   1084\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[1;32m   1085\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[1;32m   1086\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m   1087\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1088\u001b[0m )\n\u001b[1;32m   1090\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[1;32m   1092\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aml/lib/python3.10/site-packages/sklearn/utils/validation.py:899\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    894\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    895\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    896\u001b[0m         )\n\u001b[1;32m    898\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 899\u001b[0m         _assert_all_finite(\n\u001b[1;32m    900\u001b[0m             array,\n\u001b[1;32m    901\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    902\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    903\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    904\u001b[0m         )\n\u001b[1;32m    906\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    907\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aml/lib/python3.10/site-packages/sklearn/utils/validation.py:146\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    125\u001b[0m             \u001b[39mnot\u001b[39;00m allow_nan\n\u001b[1;32m    126\u001b[0m             \u001b[39mand\u001b[39;00m estimator_name\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    131\u001b[0m             \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m             msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    133\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m             )\n\u001b[0;32m--> 146\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n\u001b[1;32m    148\u001b[0m \u001b[39m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39melif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nan:\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nLasso does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "lasso = Lasso()\n",
    "lasso.fit(X_train_norm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6417ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([coef for coef in lasso.coef_ if coef!=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a058ada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd73c63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934238b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA()\n",
    "pca.fit(X_train_norm, y_train)\n",
    "\n",
    "df = pd.DataFrame({\"pca\":pca.get_feature_names_out(),\"sv\":pca.singular_values_})\n",
    "fig = px.bar(df, x='pca', y='sv')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12543797",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = pca.transform(X_train_norm)\n",
    "model = LinearRegression()\n",
    "model.fit(X_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a241dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(pca.transform(X_test))\n",
    "score = r2_score(y_test, y_pred)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eba3c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.bar(pca.get_feature_names_out(),pca.singular_values_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44d2997",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('aml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "53205f1a5bceb014cede6b4cb20e924585cbbcf89cb486efb59ab5521987e362"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
