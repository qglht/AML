{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a96534f8",
   "metadata": {},
   "source": [
    "# Project 1 - Aurèle Bohbot, Quentin Guilhot, Yanis Tournier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e3410cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as skl\n",
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, ShuffleSplit\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LassoCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bfbfee1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('data/X_train.csv').drop(columns=['id'])\n",
    "Xt = pd.read_csv('data/X_test.csv')\n",
    "y = pd.read_csv('data/y_train.csv')\n",
    "y = y.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06c242f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8774a89e",
   "metadata": {},
   "source": [
    "### Experimental section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21330ecf",
   "metadata": {},
   "source": [
    "#### Normalization of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "390e4762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing X_train\n",
    "\n",
    "X_train_norm = X_train.copy()\n",
    "for col in X_train.columns:\n",
    "    X_train_norm[col] = (X_train[col] - X_train[col].mean()) / X_train[col].std()\n",
    "\n",
    "# normalizing X_test\n",
    "X_test_norm = X_test.copy()\n",
    "for col in X_test.columns:\n",
    "    X_test_norm[col] = (X_test[col] - X_test[col].mean()) / X_test[col].std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "353d88c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning of X_train\n",
    "\n",
    "X_train_norm=X_train_norm.fillna(X_train_norm.median())\n",
    "\n",
    "# cleaning of X_test\n",
    "\n",
    "X_test_norm=X_test_norm.fillna(X_test_norm.median())\n",
    "\n",
    "# removing columns for which there are only nans\n",
    "\n",
    "columns_to_remove = []\n",
    "for column in X_test_norm.columns:\n",
    "    if X_test_norm[column].isna().sum() > 0:\n",
    "        columns_to_remove.append(column)\n",
    "\n",
    "X_train_norm.drop(columns_to_remove, inplace=True, axis=1)\n",
    "X_test_norm.drop(columns_to_remove, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d372e4f",
   "metadata": {},
   "source": [
    "First regression without any additional treatment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4093b811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024440608245360762"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=LinearRegression()\n",
    "model.fit(X_train_norm,y_train)\n",
    "\n",
    "y_pred=model.predict(X_test_norm)\n",
    "r2_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "032f1732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg=y_train.mean()\n",
    "y_pred=avg.values[0]*np.ones(X_test.shape[0])\n",
    "r2_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f4b0ac",
   "metadata": {},
   "source": [
    "### Handling outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "10209367",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg=X_train.mean()\n",
    "var=X_train.var()\n",
    "cov=X_train.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8efe2f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9530650263643888"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.997**(800/50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e28a6118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection(df,features):\n",
    "    outlier_indices=[]\n",
    "    \n",
    "    for c in features:\n",
    "        Q1, Q3 = np.percentile(df[c],25), np.percentile(df[c],75)\n",
    "        \n",
    "        #IQR calculation\n",
    "        IQR = Q3 - Q1\n",
    "        outlier_step = IQR * 1.5\n",
    "        lower_range = Q1 - (outlier_step)\n",
    "        upper_range = Q3 + (outlier_step)\n",
    "        \n",
    "        #Outlier detection                                    #Outlier indexes\n",
    "        outlier_list_col=df[  (df[c] < lower_range) | (df[c] > upper_range)  ].index\n",
    "       \n",
    "        #Store indexes\n",
    "        outlier_indices.extend(outlier_list_col)\n",
    "        \n",
    "    outlier_indices=Counter(outlier_indices)\n",
    "    # number of outliers\n",
    "    # If we have more then 2 outliers in a sample, this sample ll be drop\n",
    "    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 2 )\n",
    "    #we are taking indexes\n",
    "    \n",
    "    return multiple_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9624a01e",
   "metadata": {},
   "source": [
    "### Handling missing values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67ed714",
   "metadata": {},
   "source": [
    "For the moment, we replace the missing values by the column's median. Depending on the results, we might implement a knn algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0189f882",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filled = X_train.fillna(X_train.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2fc10528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x822</th>\n",
       "      <th>x823</th>\n",
       "      <th>x824</th>\n",
       "      <th>x825</th>\n",
       "      <th>x826</th>\n",
       "      <th>x827</th>\n",
       "      <th>x828</th>\n",
       "      <th>x829</th>\n",
       "      <th>x830</th>\n",
       "      <th>x831</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.001566</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>-1.898010e-04</td>\n",
       "      <td>-0.473492</td>\n",
       "      <td>-0.000480</td>\n",
       "      <td>-0.000385</td>\n",
       "      <td>-0.001698</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>-0.072864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>-0.000631</td>\n",
       "      <td>0.195912</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>-1.034119</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.051652</td>\n",
       "      <td>0.001229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>-0.000506</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.002455</td>\n",
       "      <td>-6.222288e-05</td>\n",
       "      <td>0.243028</td>\n",
       "      <td>-0.121647</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>-0.002193</td>\n",
       "      <td>-0.005757</td>\n",
       "      <td>-0.609136</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001448</td>\n",
       "      <td>-0.000333</td>\n",
       "      <td>-0.004205</td>\n",
       "      <td>-0.312476</td>\n",
       "      <td>0.061154</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.727801</td>\n",
       "      <td>-0.000689</td>\n",
       "      <td>0.030222</td>\n",
       "      <td>0.001004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>-0.000017</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>-3.355576e-08</td>\n",
       "      <td>-0.006433</td>\n",
       "      <td>0.069583</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.006196</td>\n",
       "      <td>-0.005941</td>\n",
       "      <td>-1.007904</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000173</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>-0.000989</td>\n",
       "      <td>-0.089989</td>\n",
       "      <td>0.235401</td>\n",
       "      <td>-0.001400</td>\n",
       "      <td>-2.217684</td>\n",
       "      <td>-0.005465</td>\n",
       "      <td>-0.058736</td>\n",
       "      <td>0.000620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>-0.000227</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>-0.000640</td>\n",
       "      <td>-1.917863e-04</td>\n",
       "      <td>0.002499</td>\n",
       "      <td>-0.319502</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>-0.005150</td>\n",
       "      <td>-0.006275</td>\n",
       "      <td>-0.917006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>-0.251294</td>\n",
       "      <td>0.086133</td>\n",
       "      <td>-0.001476</td>\n",
       "      <td>4.535187</td>\n",
       "      <td>-0.001200</td>\n",
       "      <td>0.003431</td>\n",
       "      <td>-0.000651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>-0.000103</td>\n",
       "      <td>-0.000722</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>7.499469e-05</td>\n",
       "      <td>-0.346855</td>\n",
       "      <td>0.225285</td>\n",
       "      <td>-0.001076</td>\n",
       "      <td>0.006932</td>\n",
       "      <td>0.004788</td>\n",
       "      <td>-0.399058</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000804</td>\n",
       "      <td>-0.000209</td>\n",
       "      <td>0.003437</td>\n",
       "      <td>-0.384839</td>\n",
       "      <td>-0.163415</td>\n",
       "      <td>-0.004382</td>\n",
       "      <td>-6.492582</td>\n",
       "      <td>0.003093</td>\n",
       "      <td>0.054740</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>-0.000699</td>\n",
       "      <td>-1.442587e-04</td>\n",
       "      <td>-0.306512</td>\n",
       "      <td>-0.074619</td>\n",
       "      <td>0.001326</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.001991</td>\n",
       "      <td>-0.036737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>-0.000631</td>\n",
       "      <td>0.605737</td>\n",
       "      <td>-0.246015</td>\n",
       "      <td>0.001750</td>\n",
       "      <td>-0.520480</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.010332</td>\n",
       "      <td>0.001710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>-0.000132</td>\n",
       "      <td>-0.000567</td>\n",
       "      <td>-0.001448</td>\n",
       "      <td>4.730944e-05</td>\n",
       "      <td>-0.298873</td>\n",
       "      <td>-0.045282</td>\n",
       "      <td>-0.002531</td>\n",
       "      <td>0.004641</td>\n",
       "      <td>-0.004720</td>\n",
       "      <td>-0.540256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>-0.001329</td>\n",
       "      <td>-0.557548</td>\n",
       "      <td>0.015850</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>5.579982</td>\n",
       "      <td>-0.005231</td>\n",
       "      <td>-0.048276</td>\n",
       "      <td>-0.000989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>-0.000309</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>-0.001530</td>\n",
       "      <td>-3.355576e-08</td>\n",
       "      <td>0.501975</td>\n",
       "      <td>0.017081</td>\n",
       "      <td>-0.000698</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.005510</td>\n",
       "      <td>0.613534</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000159</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>-0.000631</td>\n",
       "      <td>-0.217634</td>\n",
       "      <td>0.422561</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>1.636514</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>0.042246</td>\n",
       "      <td>0.000203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>0.003818</td>\n",
       "      <td>3.365401e-05</td>\n",
       "      <td>0.598835</td>\n",
       "      <td>-0.024605</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>-0.000512</td>\n",
       "      <td>-0.001144</td>\n",
       "      <td>-0.853322</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002345</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.007706</td>\n",
       "      <td>-0.231944</td>\n",
       "      <td>0.589076</td>\n",
       "      <td>0.003152</td>\n",
       "      <td>1.524929</td>\n",
       "      <td>0.003915</td>\n",
       "      <td>-0.008156</td>\n",
       "      <td>-0.002422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>1.094302e-04</td>\n",
       "      <td>0.250039</td>\n",
       "      <td>-0.005299</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.005601</td>\n",
       "      <td>0.377086</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000387</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>-0.000631</td>\n",
       "      <td>-0.086680</td>\n",
       "      <td>-0.430835</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>-4.212191</td>\n",
       "      <td>-0.000355</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>969 rows × 832 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x0        x1        x2            x3        x4        x5  \\\n",
       "806   0.000401  0.001566  0.000971 -1.898010e-04 -0.473492 -0.000480   \n",
       "591  -0.000506  0.000010 -0.002455 -6.222288e-05  0.243028 -0.121647   \n",
       "361  -0.000017  0.000093  0.002247 -3.355576e-08 -0.006433  0.069583   \n",
       "266  -0.000227 -0.000022 -0.000640 -1.917863e-04  0.002499 -0.319502   \n",
       "879  -0.000103 -0.000722  0.001123  7.499469e-05 -0.346855  0.225285   \n",
       "...        ...       ...       ...           ...       ...       ...   \n",
       "1044 -0.000021  0.000185 -0.000699 -1.442587e-04 -0.306512 -0.074619   \n",
       "1095 -0.000132 -0.000567 -0.001448  4.730944e-05 -0.298873 -0.045282   \n",
       "1130 -0.000309 -0.000030 -0.001530 -3.355576e-08  0.501975  0.017081   \n",
       "860   0.000496  0.000957  0.003818  3.365401e-05  0.598835 -0.024605   \n",
       "1126  0.000677  0.000666  0.001073  1.094302e-04  0.250039 -0.005299   \n",
       "\n",
       "            x6        x7        x8        x9  ...      x822      x823  \\\n",
       "806  -0.000385 -0.001698  0.000037 -0.072864  ...  0.000144  0.000465   \n",
       "591   0.000271 -0.002193 -0.005757 -0.609136  ... -0.001448 -0.000333   \n",
       "361   0.000017 -0.006196 -0.005941 -1.007904  ... -0.000173  0.000086   \n",
       "266   0.000269 -0.005150 -0.006275 -0.917006  ...  0.000226  0.000460   \n",
       "879  -0.001076  0.006932  0.004788 -0.399058  ... -0.000804 -0.000209   \n",
       "...        ...       ...       ...       ...  ...       ...       ...   \n",
       "1044  0.001326  0.000268  0.001991 -0.036737  ...  0.000127  0.000096   \n",
       "1095 -0.002531  0.004641 -0.004720 -0.540256  ...  0.000935  0.000117   \n",
       "1130 -0.000698 -0.000002  0.005510  0.613534  ... -0.000159  0.000536   \n",
       "860   0.001083 -0.000512 -0.001144 -0.853322  ... -0.002345  0.000550   \n",
       "1126  0.000209 -0.000002  0.005601  0.377086  ... -0.000387  0.000103   \n",
       "\n",
       "          x824      x825      x826      x827      x828      x829      x830  \\\n",
       "806  -0.000631  0.195912  0.002024  0.002457 -1.034119  0.004054  0.051652   \n",
       "591  -0.004205 -0.312476  0.061154  0.000112  0.727801 -0.000689  0.030222   \n",
       "361  -0.000989 -0.089989  0.235401 -0.001400 -2.217684 -0.005465 -0.058736   \n",
       "266   0.002538 -0.251294  0.086133 -0.001476  4.535187 -0.001200  0.003431   \n",
       "879   0.003437 -0.384839 -0.163415 -0.004382 -6.492582  0.003093  0.054740   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1044 -0.000631  0.605737 -0.246015  0.001750 -0.520480  0.000031  0.010332   \n",
       "1095 -0.001329 -0.557548  0.015850  0.001357  5.579982 -0.005231 -0.048276   \n",
       "1130 -0.000631 -0.217634  0.422561  0.000151  1.636514  0.002245  0.042246   \n",
       "860   0.007706 -0.231944  0.589076  0.003152  1.524929  0.003915 -0.008156   \n",
       "1126 -0.000631 -0.086680 -0.430835  0.001262 -4.212191 -0.000355  0.002747   \n",
       "\n",
       "          x831  \n",
       "806   0.001229  \n",
       "591   0.001004  \n",
       "361   0.000620  \n",
       "266  -0.000651  \n",
       "879   0.000021  \n",
       "...        ...  \n",
       "1044  0.001710  \n",
       "1095 -0.000989  \n",
       "1130  0.000203  \n",
       "860  -0.002422  \n",
       "1126  0.000086  \n",
       "\n",
       "[969 rows x 832 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_norm = X_filled.copy()\n",
    "for col in X_filled.columns:\n",
    "    X_train_norm[col] = (X_filled[col] - X_filled[col].mean()) / X_filled[col].var()\n",
    "X_train_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4a7814c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x822</th>\n",
       "      <th>x823</th>\n",
       "      <th>x824</th>\n",
       "      <th>x825</th>\n",
       "      <th>x826</th>\n",
       "      <th>x827</th>\n",
       "      <th>x828</th>\n",
       "      <th>x829</th>\n",
       "      <th>x830</th>\n",
       "      <th>x831</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.001566</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>-1.898010e-04</td>\n",
       "      <td>-0.473492</td>\n",
       "      <td>-0.000480</td>\n",
       "      <td>-0.000385</td>\n",
       "      <td>-0.001698</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>-0.072864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>-0.000631</td>\n",
       "      <td>0.195912</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>-1.034119</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.051652</td>\n",
       "      <td>0.001229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>-0.000506</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.002455</td>\n",
       "      <td>-6.222288e-05</td>\n",
       "      <td>0.243028</td>\n",
       "      <td>-0.121647</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>-0.002193</td>\n",
       "      <td>-0.005757</td>\n",
       "      <td>-0.609136</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001448</td>\n",
       "      <td>-0.000333</td>\n",
       "      <td>-0.004205</td>\n",
       "      <td>-0.312476</td>\n",
       "      <td>0.061154</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.727801</td>\n",
       "      <td>-0.000689</td>\n",
       "      <td>0.030222</td>\n",
       "      <td>0.001004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>-0.000017</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>-3.355576e-08</td>\n",
       "      <td>-0.006433</td>\n",
       "      <td>0.069583</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.006196</td>\n",
       "      <td>-0.005941</td>\n",
       "      <td>-1.007904</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000173</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>-0.000989</td>\n",
       "      <td>-0.089989</td>\n",
       "      <td>0.235401</td>\n",
       "      <td>-0.001400</td>\n",
       "      <td>-2.217684</td>\n",
       "      <td>-0.005465</td>\n",
       "      <td>-0.058736</td>\n",
       "      <td>0.000620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>-0.000227</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>-0.000640</td>\n",
       "      <td>-1.917863e-04</td>\n",
       "      <td>0.002499</td>\n",
       "      <td>-0.319502</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>-0.005150</td>\n",
       "      <td>-0.006275</td>\n",
       "      <td>-0.917006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>-0.251294</td>\n",
       "      <td>0.086133</td>\n",
       "      <td>-0.001476</td>\n",
       "      <td>4.535187</td>\n",
       "      <td>-0.001200</td>\n",
       "      <td>0.003431</td>\n",
       "      <td>-0.000651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>-0.000103</td>\n",
       "      <td>-0.000722</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>7.499469e-05</td>\n",
       "      <td>-0.346855</td>\n",
       "      <td>0.225285</td>\n",
       "      <td>-0.001076</td>\n",
       "      <td>0.006932</td>\n",
       "      <td>0.004788</td>\n",
       "      <td>-0.399058</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000804</td>\n",
       "      <td>-0.000209</td>\n",
       "      <td>0.003437</td>\n",
       "      <td>-0.384839</td>\n",
       "      <td>-0.163415</td>\n",
       "      <td>-0.004382</td>\n",
       "      <td>-6.492582</td>\n",
       "      <td>0.003093</td>\n",
       "      <td>0.054740</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>-0.000699</td>\n",
       "      <td>-1.442587e-04</td>\n",
       "      <td>-0.306512</td>\n",
       "      <td>-0.074619</td>\n",
       "      <td>0.001326</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.001991</td>\n",
       "      <td>-0.036737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>-0.000631</td>\n",
       "      <td>0.605737</td>\n",
       "      <td>-0.246015</td>\n",
       "      <td>0.001750</td>\n",
       "      <td>-0.520480</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.010332</td>\n",
       "      <td>0.001710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>-0.000132</td>\n",
       "      <td>-0.000567</td>\n",
       "      <td>-0.001448</td>\n",
       "      <td>4.730944e-05</td>\n",
       "      <td>-0.298873</td>\n",
       "      <td>-0.045282</td>\n",
       "      <td>-0.002531</td>\n",
       "      <td>0.004641</td>\n",
       "      <td>-0.004720</td>\n",
       "      <td>-0.540256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>-0.001329</td>\n",
       "      <td>-0.557548</td>\n",
       "      <td>0.015850</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>5.579982</td>\n",
       "      <td>-0.005231</td>\n",
       "      <td>-0.048276</td>\n",
       "      <td>-0.000989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>-0.000309</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>-0.001530</td>\n",
       "      <td>-3.355576e-08</td>\n",
       "      <td>0.501975</td>\n",
       "      <td>0.017081</td>\n",
       "      <td>-0.000698</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.005510</td>\n",
       "      <td>0.613534</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000159</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>-0.000631</td>\n",
       "      <td>-0.217634</td>\n",
       "      <td>0.422561</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>1.636514</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>0.042246</td>\n",
       "      <td>0.000203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>0.003818</td>\n",
       "      <td>3.365401e-05</td>\n",
       "      <td>0.598835</td>\n",
       "      <td>-0.024605</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>-0.000512</td>\n",
       "      <td>-0.001144</td>\n",
       "      <td>-0.853322</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002345</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.007706</td>\n",
       "      <td>-0.231944</td>\n",
       "      <td>0.589076</td>\n",
       "      <td>0.003152</td>\n",
       "      <td>1.524929</td>\n",
       "      <td>0.003915</td>\n",
       "      <td>-0.008156</td>\n",
       "      <td>-0.002422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>1.094302e-04</td>\n",
       "      <td>0.250039</td>\n",
       "      <td>-0.005299</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.005601</td>\n",
       "      <td>0.377086</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000387</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>-0.000631</td>\n",
       "      <td>-0.086680</td>\n",
       "      <td>-0.430835</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>-4.212191</td>\n",
       "      <td>-0.000355</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>969 rows × 832 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x0        x1        x2            x3        x4        x5  \\\n",
       "806   0.000401  0.001566  0.000971 -1.898010e-04 -0.473492 -0.000480   \n",
       "591  -0.000506  0.000010 -0.002455 -6.222288e-05  0.243028 -0.121647   \n",
       "361  -0.000017  0.000093  0.002247 -3.355576e-08 -0.006433  0.069583   \n",
       "266  -0.000227 -0.000022 -0.000640 -1.917863e-04  0.002499 -0.319502   \n",
       "879  -0.000103 -0.000722  0.001123  7.499469e-05 -0.346855  0.225285   \n",
       "...        ...       ...       ...           ...       ...       ...   \n",
       "1044 -0.000021  0.000185 -0.000699 -1.442587e-04 -0.306512 -0.074619   \n",
       "1095 -0.000132 -0.000567 -0.001448  4.730944e-05 -0.298873 -0.045282   \n",
       "1130 -0.000309 -0.000030 -0.001530 -3.355576e-08  0.501975  0.017081   \n",
       "860   0.000496  0.000957  0.003818  3.365401e-05  0.598835 -0.024605   \n",
       "1126  0.000677  0.000666  0.001073  1.094302e-04  0.250039 -0.005299   \n",
       "\n",
       "            x6        x7        x8        x9  ...      x822      x823  \\\n",
       "806  -0.000385 -0.001698  0.000037 -0.072864  ...  0.000144  0.000465   \n",
       "591   0.000271 -0.002193 -0.005757 -0.609136  ... -0.001448 -0.000333   \n",
       "361   0.000017 -0.006196 -0.005941 -1.007904  ... -0.000173  0.000086   \n",
       "266   0.000269 -0.005150 -0.006275 -0.917006  ...  0.000226  0.000460   \n",
       "879  -0.001076  0.006932  0.004788 -0.399058  ... -0.000804 -0.000209   \n",
       "...        ...       ...       ...       ...  ...       ...       ...   \n",
       "1044  0.001326  0.000268  0.001991 -0.036737  ...  0.000127  0.000096   \n",
       "1095 -0.002531  0.004641 -0.004720 -0.540256  ...  0.000935  0.000117   \n",
       "1130 -0.000698 -0.000002  0.005510  0.613534  ... -0.000159  0.000536   \n",
       "860   0.001083 -0.000512 -0.001144 -0.853322  ... -0.002345  0.000550   \n",
       "1126  0.000209 -0.000002  0.005601  0.377086  ... -0.000387  0.000103   \n",
       "\n",
       "          x824      x825      x826      x827      x828      x829      x830  \\\n",
       "806  -0.000631  0.195912  0.002024  0.002457 -1.034119  0.004054  0.051652   \n",
       "591  -0.004205 -0.312476  0.061154  0.000112  0.727801 -0.000689  0.030222   \n",
       "361  -0.000989 -0.089989  0.235401 -0.001400 -2.217684 -0.005465 -0.058736   \n",
       "266   0.002538 -0.251294  0.086133 -0.001476  4.535187 -0.001200  0.003431   \n",
       "879   0.003437 -0.384839 -0.163415 -0.004382 -6.492582  0.003093  0.054740   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1044 -0.000631  0.605737 -0.246015  0.001750 -0.520480  0.000031  0.010332   \n",
       "1095 -0.001329 -0.557548  0.015850  0.001357  5.579982 -0.005231 -0.048276   \n",
       "1130 -0.000631 -0.217634  0.422561  0.000151  1.636514  0.002245  0.042246   \n",
       "860   0.007706 -0.231944  0.589076  0.003152  1.524929  0.003915 -0.008156   \n",
       "1126 -0.000631 -0.086680 -0.430835  0.001262 -4.212191 -0.000355  0.002747   \n",
       "\n",
       "          x831  \n",
       "806   0.001229  \n",
       "591   0.001004  \n",
       "361   0.000620  \n",
       "266  -0.000651  \n",
       "879   0.000021  \n",
       "...        ...  \n",
       "1044  0.001710  \n",
       "1095 -0.000989  \n",
       "1130  0.000203  \n",
       "860  -0.002422  \n",
       "1126  0.000086  \n",
       "\n",
       "[969 rows x 832 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {}\n",
    "for col in X_train_norm.columns:\n",
    "    Q1, Q3 = np.percentile(X_train_norm[col],25), np.percentile(X_train_norm[col],75)\n",
    "    IQR = Q3 - Q1\n",
    "    outlier_step = IQR * 2\n",
    "    lower_range = Q1 - (outlier_step)\n",
    "    upper_range = Q3 + (outlier_step)\n",
    "    d[col] = (lower_range, upper_range)\n",
    "for i, row in X_train_norm.iterrows():\n",
    "    for col in X_train_norm.columns:\n",
    "        if row[col] < d[col][0] or row[col] > d[col][1]:\n",
    "            X_train_norm.loc[i,col]=0\n",
    "X_train_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5d3228",
   "metadata": {},
   "source": [
    "### Handling feature selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "72780940",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLasso does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/qguilhot/Documents/projet_aml/AML/Project1bis.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/qguilhot/Documents/projet_aml/AML/Project1bis.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m lasso \u001b[39m=\u001b[39m Lasso()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/qguilhot/Documents/projet_aml/AML/Project1bis.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m lasso\u001b[39m.\u001b[39;49mfit(X_train_norm, y_train)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aml/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:955\u001b[0m, in \u001b[0;36mElasticNet.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[39mif\u001b[39;00m check_input:\n\u001b[1;32m    954\u001b[0m     X_copied \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy_X \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_intercept\n\u001b[0;32m--> 955\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    956\u001b[0m         X,\n\u001b[1;32m    957\u001b[0m         y,\n\u001b[1;32m    958\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    959\u001b[0m         order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mF\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    960\u001b[0m         dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32],\n\u001b[1;32m    961\u001b[0m         copy\u001b[39m=\u001b[39;49mX_copied,\n\u001b[1;32m    962\u001b[0m         multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    963\u001b[0m         y_numeric\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    964\u001b[0m     )\n\u001b[1;32m    965\u001b[0m     y \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m    966\u001b[0m         y, order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mF\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    967\u001b[0m     )\n\u001b[1;32m    969\u001b[0m n_samples, n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aml/lib/python3.10/site-packages/sklearn/base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    594\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    595\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aml/lib/python3.10/site-packages/sklearn/utils/validation.py:1074\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1069\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1070\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1071\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1072\u001b[0m     )\n\u001b[0;32m-> 1074\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1075\u001b[0m     X,\n\u001b[1;32m   1076\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m   1077\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[1;32m   1078\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1079\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[1;32m   1080\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   1081\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m   1082\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[1;32m   1083\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[1;32m   1084\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[1;32m   1085\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[1;32m   1086\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m   1087\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1088\u001b[0m )\n\u001b[1;32m   1090\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[1;32m   1092\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aml/lib/python3.10/site-packages/sklearn/utils/validation.py:899\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    894\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    895\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    896\u001b[0m         )\n\u001b[1;32m    898\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 899\u001b[0m         _assert_all_finite(\n\u001b[1;32m    900\u001b[0m             array,\n\u001b[1;32m    901\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    902\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    903\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    904\u001b[0m         )\n\u001b[1;32m    906\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    907\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aml/lib/python3.10/site-packages/sklearn/utils/validation.py:146\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    125\u001b[0m             \u001b[39mnot\u001b[39;00m allow_nan\n\u001b[1;32m    126\u001b[0m             \u001b[39mand\u001b[39;00m estimator_name\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    131\u001b[0m             \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m             msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    133\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m             )\n\u001b[0;32m--> 146\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n\u001b[1;32m    148\u001b[0m \u001b[39m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39melif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nan:\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nLasso does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "lasso = Lasso()\n",
    "lasso.fit(X_train_norm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6417ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([coef for coef in lasso.coef_ if coef!=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a058ada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd73c63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934238b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA()\n",
    "pca.fit(X_train_norm, y_train)\n",
    "\n",
    "df = pd.DataFrame({\"pca\":pca.get_feature_names_out(),\"sv\":pca.singular_values_})\n",
    "fig = px.bar(df, x='pca', y='sv')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12543797",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = pca.transform(X_train_norm)\n",
    "model = LinearRegression()\n",
    "model.fit(X_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a241dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(pca.transform(X_test))\n",
    "score = r2_score(y_test, y_pred)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eba3c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.bar(pca.get_feature_names_out(),pca.singular_values_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44d2997",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('aml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "53205f1a5bceb014cede6b4cb20e924585cbbcf89cb486efb59ab5521987e362"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
